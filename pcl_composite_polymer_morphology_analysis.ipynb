{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T23:50:25.550217",
     "start_time": "2017-04-21T23:50:23.144114"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ws/ih7618/anaconda2/lib/python2.7/site-packages/matplotlib/__init__.py:913: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.ndimage as ndi\n",
    "from skimage import measure, io\n",
    "import matplotlib.pyplot as plt\n",
    "import mahotas as mh\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T23:50:26.279955",
     "start_time": "2017-04-21T23:50:26.272194"
    }
   },
   "outputs": [],
   "source": [
    "def parse_filename(filepath):\n",
    "    basename, ext = os.path.splitext(os.path.basename(filepath))\n",
    "\n",
    "    comps = basename.split('_')\n",
    "    size = tuple([int(v) for v in comps[-1:][0].split('x')])\n",
    "    bits = int(re.findall('\\d+', comps[-2:-1][0])[0])\n",
    "    name = '_'.join(comps[:-2])\n",
    "\n",
    "    return name, bits, size, ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T23:50:27.075946",
     "start_time": "2017-04-21T23:50:27.071351"
    }
   },
   "outputs": [],
   "source": [
    "def segment_data(filepath):\n",
    "    data = open_data(filepath)\n",
    "    # apply 3D median filter 2x2x2\n",
    "    # calculate Reyni thresholding\n",
    "    # crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T23:50:27.659247",
     "start_time": "2017-04-21T23:50:27.648762"
    }
   },
   "outputs": [],
   "source": [
    "def open_data(filepath):\n",
    "    _, glob_ext = os.path.splitext(os.path.basename(filepath))\n",
    "    data = None\n",
    "\n",
    "    if glob_ext == '.raw':\n",
    "        name, bits, size, ext = parse_filename(filepath)\n",
    "        data_type = np.float32 if bits == 32 else np.uint8\n",
    "        data = np.memmap(filepath, dtype=data_type, shape=tuple(reversed(size)), mode='r')\n",
    "    elif glob_ext == '.nii.gz' or glob_ext == '.nii' or glob_ext == '.gz':\n",
    "        data = nib.load(filepath).get_data()\n",
    "    elif glob_ext == '.tif':\n",
    "        data = io.imread(filepath)\n",
    "    else:\n",
    "        print 'Incorrent file format, or filename.'\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-23T15:04:22.898866",
     "start_time": "2017-04-23T15:04:22.890785"
    }
   },
   "outputs": [],
   "source": [
    "def save_fig(fig, output_filepath):\n",
    "    output_path, filename = os.path.split(output_filepath)\n",
    "        \n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    \n",
    "    print output_filepath\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fig.savefig(output_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T23:50:28.407353",
     "start_time": "2017-04-21T23:50:28.399667"
    }
   },
   "outputs": [],
   "source": [
    "def write_as_raw(data, sample_name, output_dir, prefix=None):\n",
    "    bits = -1\n",
    "    if data.dtype == np.int32 or data.dtype == np.float32:\n",
    "        bits = 32\n",
    "    elif data.dtype == np.uint8 or data.dtype == np.bool:\n",
    "        bits = 8\n",
    "\n",
    "    size = data.shape[::-1]\n",
    "    output_filename = '{0}_{1}bit_{2}x{3}x{4}.raw'.format(sample_name, bits, *size) if prefix is None \\\n",
    "                        else '{0}_{1}_{2}bit_{3}x{4}x{5}.raw'.format(sample_name, prefix, bits, *size)\n",
    "    data.tofile(os.path.join(output_dir, output_filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T23:50:30.148747",
     "start_time": "2017-04-21T23:50:30.131511"
    }
   },
   "outputs": [],
   "source": [
    "_MEASUREMENTS = {\n",
    "    'Label': 'label',\n",
    "    'Area': 'area',\n",
    "    'Perimeter': 'perimeter'\n",
    "}\n",
    "\n",
    "_MEASUREMENTS_VALS = _MEASUREMENTS.values()\n",
    "\n",
    "def object_counter(stack_binary_data):\n",
    "    print 'Object counting - Labeling...'\n",
    "    labeled_stack, num_labels = ndi.measurements.label(stack_binary_data)\n",
    "    objects_stats = pd.DataFrame(columns=_MEASUREMENTS_VALS)\n",
    "    \n",
    "    print 'Object counting - Stats gathering...'\n",
    "    for slice_idx in np.arange(labeled_stack.shape[0]):\n",
    "        for region in measure.regionprops(labeled_stack[slice_idx]):\n",
    "            objects_stats = objects_stats.append({_measure: region[_measure] \\\n",
    "                                        for _measure in _MEASUREMENTS_VALS}, \\\n",
    "                                            ignore_index=True)\n",
    "            \n",
    "    print 'Object counting - Stats grouping...'\n",
    "    objects_stats = objects_stats.groupby('label', as_index=False).sum()\n",
    "\n",
    "    return objects_stats, labeled_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T23:50:30.986174",
     "start_time": "2017-04-21T23:50:30.976405"
    }
   },
   "outputs": [],
   "source": [
    "def estimate_particles(samples, output_dir, parts=None):\n",
    "    for sample_name, params in samples['samples'].items():\n",
    "        if 'particles' in params:\n",
    "            print '###### Processing of {}'.format(sample_name)\n",
    "\n",
    "            print 'Data processing - Opening...'\n",
    "            input_data = open_data(os.path.join(samples['input_dir'], params['particles'][0]))\n",
    "        \n",
    "            if parts is not None:\n",
    "                input_data = split_dataset(input_data, parts=parts)\n",
    "                \n",
    "                for i, dp in enumerate(input_data):\n",
    "                    dp_objects_stats, dp_labeled_data = object_counter(dp)\n",
    "                    output_path = os.path.join(output_dir, sample_name, 'part_{}'.format(i))\n",
    "                    \n",
    "                    print 'Data storing (Part #{}) - Stats and data saving...'.format(i)\n",
    "                    if not os.path.exists(output_path):\n",
    "                        os.makedirs(output_path)\n",
    "                        \n",
    "                    dp_objects_stats.to_csv(os.path.join(output_path, 'particles_stats_{}_part{}.csv'.format(sample_name, i)))\n",
    "            else:\n",
    "                objects_stats, labeled_data = object_counter(input_data)\n",
    "                output_path = os.path.join(output_dir, sample_name)\n",
    "\n",
    "                print 'Data storing - Stats and data saving...'\n",
    "                if not os.path.exists(output_path):\n",
    "                    os.makedirs(output_path)\n",
    "\n",
    "                objects_stats.to_csv(os.path.join(output_path, 'particles_stats_{}.csv'.format(sample_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_porosity(samples, output_dir=None, parts=None):\n",
    "    for sample_name, sample_info in samples['samples'].items():\n",
    "        print '###### Processing of {}'.format(sample_name)\n",
    "        \n",
    "        if parts is not None:\n",
    "            total_volume_dp, material_volume_dp = [0]*(parts[0]*parts[1]), [0]*(parts[0]*parts[1])\n",
    "            \n",
    "            for structure_type, data_params in sample_info.items():\n",
    "                input_data = open_data(os.path.join(samples['input_dir'], data_params[0]))\n",
    "                input_data = split_dataset(input_data, parts=parts)\n",
    "                \n",
    "                for i, dp in enumerate(input_data):\n",
    "                    if not total_volume_dp[i]:\n",
    "                        total_volume_dp[i] = dp.size\n",
    "                        \n",
    "                    material_volume_dp[i] += np.count_nonzero(dp)\n",
    "                    \n",
    "            for i in xrange(len(total_volume_dp)):\n",
    "                output_path = os.path.join(output_dir, sample_name, 'part_{}'.format(i))\n",
    "                \n",
    "                print 'Data storing - Stats and data saving (Part #{})...'.format(i)\n",
    "                \n",
    "                if not os.path.exists(output_path):\n",
    "                    os.makedirs(output_path)\n",
    "                    \n",
    "                mt = material_volume_dp[i] / float(total_volume_dp[i])\n",
    "                porosity = 1. - mt\n",
    "                print 'Porosity :{}'.format(porosity)\n",
    "                \n",
    "                np.savetxt(os.path.join(output_path, 'porosity_{}_part{}.txt'.format(sample_name, i)), [porosity])\n",
    "        else:\n",
    "            total_volume, material_volume = None, 0\n",
    "        \n",
    "            for structure_type, data_params in sample_info.items():\n",
    "                print 'Data processing - Opening...'\n",
    "            \n",
    "                input_data = open_data(os.path.join(samples['input_dir'], data_params[0]))\n",
    "                \n",
    "                if data_params[3] is not None:\n",
    "                    input_data = input_data[data_params[3]]\n",
    "            \n",
    "                if total_volume is None:\n",
    "                    total_volume = input_data.size\n",
    "                \n",
    "                material_volume += np.count_nonzero(input_data)\n",
    "            \n",
    "            if output_dir is not None:\n",
    "                output_path = os.path.join(output_dir, sample_name)\n",
    "            \n",
    "                print 'Data storing - Stats and data saving...'\n",
    "                if not os.path.exists(output_path):\n",
    "                    os.makedirs(output_path)\n",
    "            \n",
    "            mt = material_volume / float(total_volume)\n",
    "            porosity = 1. - mt\n",
    "            print 'Porosity: {0}'.format(porosity)\n",
    "            \n",
    "            if output_dir is not None:\n",
    "                np.savetxt(os.path.join(output_path, 'porosity_{0}.txt'.format(sample_name)), [porosity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_codirectionality(samples, output_dir, parts=None):\n",
    "    for sample_name, params in samples['samples'].items():\n",
    "        print '###### Processing of {}'.format(sample_name)\n",
    "        \n",
    "        data = np.load(os.path.join(samples['input_dir'], params['fibers'][0])).item()\n",
    "        \n",
    "        for key in params['fibers'][1]:\n",
    "            input_data = data[key]\n",
    "            input_data = np.rad2deg(input_data)\n",
    "        \n",
    "            print 'Data processing - Opening...'\n",
    "            input_data = split_dataset(input_data, parts=parts)\n",
    "                \n",
    "            for i, dp in enumerate(input_data):\n",
    "                dp = dp[np.where(dp > 0)]\n",
    "\n",
    "                output_path = os.path.join(output_dir, sample_name, 'part_{}'.format(i))\n",
    "                    \n",
    "                print 'Data storing (Part #{}) - Stats and data saving...'.format(i)\n",
    "                if not os.path.exists(output_path):\n",
    "                    os.makedirs(output_path)\n",
    "                \n",
    "                pd.DataFrame({'orientation': dp}).to_csv(os.path.join(output_path, 'orientation_{}_{}_part{}.csv').format(sample_name, key, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_diameter(samples, output_dir, parts=None):\n",
    "    for sample_name, params in samples['samples'].items():\n",
    "        print '###### Processing of {}'.format(sample_name)\n",
    "        \n",
    "        input_data = np.load(os.path.join(samples['input_dir'], params['fibers'][0])).item()[params['fibers'][1]]\n",
    "        input_data = np.rad2deg(input_data)\n",
    "        \n",
    "        print 'Data processing - Opening...'\n",
    "        input_data = split_dataset(input_data, parts=parts)\n",
    "                \n",
    "        for i, dp in enumerate(input_data):\n",
    "            dp = dp.ravel()\n",
    "\n",
    "            output_path = os.path.join(output_dir, sample_name, 'part_{}'.format(i))\n",
    "                    \n",
    "            print 'Data storing (Part #{}) - Stats and data saving...'.format(i)\n",
    "            if not os.path.exists(output_path):\n",
    "                os.makedirs(output_path)\n",
    "                \n",
    "            pd.DataFrame({'diameter': dp}).to_csv(os.path.join(output_path, 'diameter_{}_part{}.csv').format(sample_name, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(data, parts=(3,3)):\n",
    "    y_idxs = np.array_split(np.arange(data.shape[1]), 3)\n",
    "    x_idxs = np.array_split(np.arange(data.shape[2]), 3)\n",
    "    \n",
    "    out_datasets = []\n",
    "    \n",
    "    for i in xrange(parts[0]):\n",
    "        for j in xrange(parts[1]):\n",
    "            out_datasets.append(data[:, slice(y_idxs[i][0],y_idxs[i][-1]), slice(x_idxs[j][0],x_idxs[j][-1])])\n",
    "            \n",
    "    return out_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-21T23:50:33.437927",
     "start_time": "2017-04-21T23:50:33.424428"
    }
   },
   "outputs": [],
   "source": [
    "config_samples = {\n",
    "    'input_dir': './raw_polymer_data/cropped',\n",
    "    'samples': {\n",
    "        'PCL_SiHA_cl': {\n",
    "            'particles': ('PCL9%_Si-HA10%_cl/analysis/particles_PCL9%_Si-HA10%_cl_32bit_800x800x351.tif', np.uint8, (351,800,800), None),\n",
    "            'fibers': ('PCL9%_Si-HA10%_cl/analysis/fibers_PCL9%_Si-HA10%_cl_8bit_800x800x351.raw', np.uint8, (351,800,800), None)\n",
    "        }\n",
    "        ,\n",
    "        'PCL_SiHA_wa': {\n",
    "            'particles':('PCL9%_Si-HA10%_wa/analysis/particles_PCL9%_Si-HA10%_wa_32bit_800x800x351.tif', np.uint8, (351,800,800), None),\n",
    "            'fibers': ('PCL9%_Si-HA10%_wa/analysis/fibers_PCL9%_Si-HA10%_wa_8bit_800x800x351.raw', np.uint8, (351,800,800), None)\n",
    "        },\n",
    "        'PCL_cl': { #30-90\n",
    "            'fibers': ('PCL_9%_cl/analysis/fiber_mask_PCL_cl_8bit_800x800x221.raw', np.uint8, (221,800,800), (30,60))\n",
    "        },\n",
    "        'PCL_wa': {#35-170\n",
    "            'fibers': ('PCL_9%_wa/analysis/fiber_mask_PCL_9%_wa_8bit_800x800x251.raw', np.uint8, (251,800,800), (35,170)),\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_samples_new = {\n",
    "    'input_dir': './raw_polymer_data/cropped',\n",
    "    'samples': {\n",
    "        'PCL_SiHA_cl': {\n",
    "            'particles': ('PCL9%_Si-HA10%_cl/analysis/fibers_PCL9%_Si-HA10%_cl_32bit_800x800x484.tif', np.uint8, (484,800,800), None)\n",
    "        },\n",
    "        'PCL_SiHA_wa': {\n",
    "            'particles':('PCL9%_Si-HA10%_wa/analysis/fibers_PCL9%_Si-HA10%_wa_8bit_800x800x351.raw', np.uint8, (351,800,800), None)\n",
    "        },\n",
    "        'PCL_cl': { #30-90\n",
    "            'fibers': ('PCL_9%_cl/analysis/fiber_mask_porosity2_PCL_cl_8bit_800x800x121.raw', np.uint8, (91,800,800), None)\n",
    "        },\n",
    "        'PCL_wa': {#35-170\n",
    "            'fibers': ('PCL_9%_wa/analysis/fiber_mask_porosity_PCL_9%_wa_8bit_800x800x141.raw', np.uint8, (141,800,800), None),\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_orient_samples = {\n",
    "    'input_dir': './raw_polymer_data/results',\n",
    "    'samples': {\n",
    "        'PCL_SiHA_cl': {\n",
    "            'fibers': ('PCL_SiHA_cl_w31_orientation_evaluation.npy', ('azth', 'lat'))\n",
    "        },\n",
    "        'PCL_SiHA_wa': {\n",
    "            'fibers': ('PCL_SiHA_wa_w31_orientation_evaluation.npy', ('azth', 'lat'))\n",
    "        },\n",
    "        'PCL_cl': {\n",
    "            'fibers': ('PCL_cl_w31_orientation_evaluation.npy', ('azth', 'lat'))\n",
    "        },\n",
    "        'PCL_wa': {\n",
    "            'fibers': ('PCL_wa_w31_orientation_evaluation.npy', ('azth', 'lat')),\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_diameter_samples = {\n",
    "    'input_dir': './raw_polymer_data/results',\n",
    "    'samples': {\n",
    "        'PCL_SiHA_cl': {\n",
    "            'fibers': ('PCL_SiHA_cl_diameter_evaluation.npy', ('diameter'))\n",
    "        },\n",
    "        'PCL_SiHA_wa': {\n",
    "            'fibers': ('PCL_SiHA_wa_diameter_evaluation.npy', ('diameter'))\n",
    "        },\n",
    "        'PCL_cl': {\n",
    "            'fibers': ('PCL_cl_diameter_evaluation.npy', ('diameter'))\n",
    "        },\n",
    "        'PCL_wa': {\n",
    "            'fibers': ('PCL_wa_diameter_evaluation.npy', ('diameter'))\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Processing of PCL_SiHA_cl\n",
      "Data processing - Opening...\n",
      "Object counting - Labeling...\n",
      "Object counting - Stats gathering...\n",
      "Object counting - Stats grouping...\n",
      "Data storing - Stats and data saving...\n"
     ]
    }
   ],
   "source": [
    "estimate_particles(config_samples, './data/results', parts=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Processing of PCL_SiHA_cl\n",
      "Data processing - Opening...\n",
      "Object counting - Labeling...\n",
      "Object counting - Stats gathering...\n",
      "Object counting - Stats grouping...\n",
      "Data storing (Part #0) - Stats and data saving...\n",
      "Object counting - Labeling...\n",
      "Object counting - Stats gathering...\n",
      "Object counting - Stats grouping...\n",
      "Data storing (Part #1) - Stats and data saving...\n",
      "Object counting - Labeling...\n",
      "Object counting - Stats gathering...\n",
      "Object counting - Stats grouping...\n",
      "Data storing (Part #2) - Stats and data saving...\n",
      "Object counting - Labeling...\n",
      "Object counting - Stats gathering...\n",
      "Object counting - Stats grouping...\n",
      "Data storing (Part #3) - Stats and data saving...\n",
      "Object counting - Labeling...\n",
      "Object counting - Stats gathering...\n",
      "Object counting - Stats grouping...\n",
      "Data storing (Part #4) - Stats and data saving...\n",
      "Object counting - Labeling...\n",
      "Object counting - Stats gathering...\n",
      "Object counting - Stats grouping...\n",
      "Data storing (Part #5) - Stats and data saving...\n",
      "Object counting - Labeling...\n",
      "Object counting - Stats gathering...\n",
      "Object counting - Stats grouping...\n",
      "Data storing (Part #6) - Stats and data saving...\n",
      "Object counting - Labeling...\n",
      "Object counting - Stats gathering...\n",
      "Object counting - Stats grouping...\n",
      "Data storing (Part #7) - Stats and data saving...\n",
      "Object counting - Labeling...\n",
      "Object counting - Stats gathering...\n",
      "Object counting - Stats grouping...\n",
      "Data storing (Part #8) - Stats and data saving...\n",
      "###### Processing of PCL_SiHA_wa\n",
      "Data processing - Opening...\n",
      "Object counting - Labeling...\n",
      "Object counting - Stats gathering...\n",
      "Object counting - Stats grouping...\n",
      "Data storing (Part #0) - Stats and data saving...\n",
      "Object counting - Labeling...\n",
      "Object counting - Stats gathering...\n",
      "Object counting - Stats grouping...\n",
      "Data storing (Part #1) - Stats and data saving...\n",
      "Object counting - Labeling...\n",
      "Object counting - Stats gathering...\n",
      "Object counting - Stats grouping...\n",
      "Data storing (Part #2) - Stats and data saving...\n",
      "Object counting - Labeling...\n",
      "Object counting - Stats gathering...\n",
      "Object counting - Stats grouping...\n",
      "Data storing (Part #3) - Stats and data saving...\n",
      "Object counting - Labeling...\n",
      "Object counting - Stats gathering...\n",
      "Object counting - Stats grouping...\n",
      "Data storing (Part #4) - Stats and data saving...\n",
      "Object counting - Labeling...\n",
      "Object counting - Stats gathering...\n",
      "Object counting - Stats grouping...\n",
      "Data storing (Part #5) - Stats and data saving...\n",
      "Object counting - Labeling...\n",
      "Object counting - Stats gathering...\n",
      "Object counting - Stats grouping...\n",
      "Data storing (Part #6) - Stats and data saving...\n",
      "Object counting - Labeling...\n",
      "Object counting - Stats gathering...\n",
      "Object counting - Stats grouping...\n",
      "Data storing (Part #7) - Stats and data saving...\n",
      "Object counting - Labeling...\n",
      "Object counting - Stats gathering...\n",
      "Object counting - Stats grouping...\n",
      "Data storing (Part #8) - Stats and data saving...\n"
     ]
    }
   ],
   "source": [
    "estimate_particles(config_samples, './data/results', parts=(3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate porosity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-30T16:42:39.280468",
     "start_time": "2017-03-30T16:42:22.199386"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Processing of PCL_cl\n",
      "Data processing - Opening...\n",
      "Data storing - Stats and data saving...\n",
      "Porosity: 0.83875627121\n",
      "###### Processing of PCL_SiHA_cl\n",
      "Data processing - Opening...\n",
      "Data processing - Opening...\n",
      "Data storing - Stats and data saving...\n",
      "Porosity: 0.740096416489\n",
      "###### Processing of PCL_SiHA_wa\n",
      "Data processing - Opening...\n",
      "Data processing - Opening...\n",
      "Data storing - Stats and data saving...\n",
      "Porosity: 0.731141706731\n",
      "###### Processing of PCL_wa\n",
      "Data processing - Opening...\n",
      "Data storing - Stats and data saving...\n",
      "Porosity: 0.761474962649\n"
     ]
    }
   ],
   "source": [
    "estimate_porosity(config_samples, output_dir='./data/results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Processing of PCL_cl\n",
      "Data processing - Opening...\n",
      "Data storing - Stats and data saving...\n",
      "Porosity: 0.771454907025\n",
      "###### Processing of PCL_SiHA_cl\n",
      "Data processing - Opening...\n",
      "Data storing - Stats and data saving...\n",
      "Porosity: 0.783606898889\n",
      "###### Processing of PCL_SiHA_wa\n",
      "Data processing - Opening...\n",
      "Data storing - Stats and data saving...\n",
      "Porosity: 0.735002581909\n",
      "###### Processing of PCL_wa\n",
      "Data processing - Opening...\n",
      "Data storing - Stats and data saving...\n",
      "Porosity: 0.722717198582\n"
     ]
    }
   ],
   "source": [
    "estimate_porosity(config_samples_new, output_dir='./data/results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split orientation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Processing of PCL_cl\n",
      "Data processing - Opening...\n",
      "Data storing (Part #0) - Stats and data saving...\n",
      "Data storing (Part #1) - Stats and data saving...\n",
      "Data storing (Part #2) - Stats and data saving...\n",
      "Data storing (Part #3) - Stats and data saving...\n",
      "Data storing (Part #4) - Stats and data saving...\n",
      "Data storing (Part #5) - Stats and data saving...\n",
      "Data storing (Part #6) - Stats and data saving...\n",
      "Data storing (Part #7) - Stats and data saving...\n",
      "Data storing (Part #8) - Stats and data saving...\n",
      "Data processing - Opening...\n",
      "Data storing (Part #0) - Stats and data saving...\n",
      "Data storing (Part #1) - Stats and data saving...\n",
      "Data storing (Part #2) - Stats and data saving...\n",
      "Data storing (Part #3) - Stats and data saving...\n",
      "Data storing (Part #4) - Stats and data saving...\n",
      "Data storing (Part #5) - Stats and data saving...\n",
      "Data storing (Part #6) - Stats and data saving...\n",
      "Data storing (Part #7) - Stats and data saving...\n",
      "Data storing (Part #8) - Stats and data saving...\n",
      "###### Processing of PCL_SiHA_cl\n",
      "Data processing - Opening...\n",
      "Data storing (Part #0) - Stats and data saving...\n",
      "Data storing (Part #1) - Stats and data saving...\n",
      "Data storing (Part #2) - Stats and data saving...\n",
      "Data storing (Part #3) - Stats and data saving...\n",
      "Data storing (Part #4) - Stats and data saving...\n",
      "Data storing (Part #5) - Stats and data saving...\n",
      "Data storing (Part #6) - Stats and data saving...\n",
      "Data storing (Part #7) - Stats and data saving...\n",
      "Data storing (Part #8) - Stats and data saving...\n",
      "Data processing - Opening...\n",
      "Data storing (Part #0) - Stats and data saving...\n",
      "Data storing (Part #1) - Stats and data saving...\n",
      "Data storing (Part #2) - Stats and data saving...\n",
      "Data storing (Part #3) - Stats and data saving...\n",
      "Data storing (Part #4) - Stats and data saving...\n",
      "Data storing (Part #5) - Stats and data saving...\n",
      "Data storing (Part #6) - Stats and data saving...\n",
      "Data storing (Part #7) - Stats and data saving...\n",
      "Data storing (Part #8) - Stats and data saving...\n",
      "###### Processing of PCL_SiHA_wa\n",
      "Data processing - Opening...\n",
      "Data storing (Part #0) - Stats and data saving...\n",
      "Data storing (Part #1) - Stats and data saving...\n",
      "Data storing (Part #2) - Stats and data saving...\n",
      "Data storing (Part #3) - Stats and data saving...\n",
      "Data storing (Part #4) - Stats and data saving...\n",
      "Data storing (Part #5) - Stats and data saving...\n",
      "Data storing (Part #6) - Stats and data saving...\n",
      "Data storing (Part #7) - Stats and data saving...\n",
      "Data storing (Part #8) - Stats and data saving...\n",
      "Data processing - Opening...\n",
      "Data storing (Part #0) - Stats and data saving...\n",
      "Data storing (Part #1) - Stats and data saving...\n",
      "Data storing (Part #2) - Stats and data saving...\n",
      "Data storing (Part #3) - Stats and data saving...\n",
      "Data storing (Part #4) - Stats and data saving...\n",
      "Data storing (Part #5) - Stats and data saving...\n",
      "Data storing (Part #6) - Stats and data saving...\n",
      "Data storing (Part #7) - Stats and data saving...\n",
      "Data storing (Part #8) - Stats and data saving...\n",
      "###### Processing of PCL_wa\n",
      "Data processing - Opening...\n",
      "Data storing (Part #0) - Stats and data saving...\n",
      "Data storing (Part #1) - Stats and data saving...\n",
      "Data storing (Part #2) - Stats and data saving...\n",
      "Data storing (Part #3) - Stats and data saving...\n",
      "Data storing (Part #4) - Stats and data saving...\n",
      "Data storing (Part #5) - Stats and data saving...\n",
      "Data storing (Part #6) - Stats and data saving...\n",
      "Data storing (Part #7) - Stats and data saving...\n",
      "Data storing (Part #8) - Stats and data saving...\n",
      "Data processing - Opening...\n",
      "Data storing (Part #0) - Stats and data saving...\n",
      "Data storing (Part #1) - Stats and data saving...\n",
      "Data storing (Part #2) - Stats and data saving...\n",
      "Data storing (Part #3) - Stats and data saving...\n",
      "Data storing (Part #4) - Stats and data saving...\n",
      "Data storing (Part #5) - Stats and data saving...\n",
      "Data storing (Part #6) - Stats and data saving...\n",
      "Data storing (Part #7) - Stats and data saving...\n",
      "Data storing (Part #8) - Stats and data saving...\n"
     ]
    }
   ],
   "source": [
    "estimate_codirectionality(config_orient_samples, './data/results', parts=(3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split diameter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Processing of PCL_cl\n",
      "Data processing - Opening...\n",
      "Data storing (Part #0) - Stats and data saving...\n",
      "Data storing (Part #1) - Stats and data saving...\n",
      "Data storing (Part #2) - Stats and data saving...\n",
      "Data storing (Part #3) - Stats and data saving...\n",
      "Data storing (Part #4) - Stats and data saving...\n",
      "Data storing (Part #5) - Stats and data saving...\n",
      "Data storing (Part #6) - Stats and data saving...\n",
      "Data storing (Part #7) - Stats and data saving...\n",
      "Data storing (Part #8) - Stats and data saving...\n",
      "###### Processing of PCL_SiHA_cl\n",
      "Data processing - Opening...\n",
      "Data storing (Part #0) - Stats and data saving...\n",
      "Data storing (Part #1) - Stats and data saving...\n",
      "Data storing (Part #2) - Stats and data saving...\n",
      "Data storing (Part #3) - Stats and data saving...\n",
      "Data storing (Part #4) - Stats and data saving...\n",
      "Data storing (Part #5) - Stats and data saving...\n",
      "Data storing (Part #6) - Stats and data saving...\n",
      "Data storing (Part #7) - Stats and data saving...\n",
      "Data storing (Part #8) - Stats and data saving...\n",
      "###### Processing of PCL_SiHA_wa\n",
      "Data processing - Opening...\n",
      "Data storing (Part #0) - Stats and data saving...\n",
      "Data storing (Part #1) - Stats and data saving...\n",
      "Data storing (Part #2) - Stats and data saving...\n",
      "Data storing (Part #3) - Stats and data saving...\n",
      "Data storing (Part #4) - Stats and data saving...\n",
      "Data storing (Part #5) - Stats and data saving...\n",
      "Data storing (Part #6) - Stats and data saving...\n",
      "Data storing (Part #7) - Stats and data saving...\n",
      "Data storing (Part #8) - Stats and data saving...\n",
      "###### Processing of PCL_wa\n",
      "Data processing - Opening...\n",
      "Data storing (Part #0) - Stats and data saving...\n",
      "Data storing (Part #1) - Stats and data saving...\n",
      "Data storing (Part #2) - Stats and data saving...\n",
      "Data storing (Part #3) - Stats and data saving...\n",
      "Data storing (Part #4) - Stats and data saving...\n",
      "Data storing (Part #5) - Stats and data saving...\n",
      "Data storing (Part #6) - Stats and data saving...\n",
      "Data storing (Part #7) - Stats and data saving...\n",
      "Data storing (Part #8) - Stats and data saving...\n"
     ]
    }
   ],
   "source": [
    "estimate_diameter(config_diameter_samples, './data/results', parts=(3,3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
